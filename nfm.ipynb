{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21825b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Factorization Machine Model\n",
    "# Written by Fernando Abel Malca Luque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa494774",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'csv_path':       'used_cars.csv',\n",
    "    'drop_cols':      ['ext_col', 'int_col', 'clean_title'],\n",
    "    'categorical_cols':['brand', 'model', 'fuel_type', 'engine', 'transmission', 'accident'],\n",
    "    'numeric_cols':   ['model_year', 'milage'],\n",
    "    'target_col':     'price',\n",
    "    'train_size':     0.7,       \n",
    "    'val_size':       0.15,       \n",
    "    'test_size':      0.15,       \n",
    "    'random_state':   123,\n",
    "\n",
    "    'embed_dim':      16,         \n",
    "    'mlp_dims':       [256, 128, 64],\n",
    "    'dropout':        0.2,      \n",
    "\n",
    "    'batch_size':     128,       \n",
    "    'num_epochs':     2000,        \n",
    "    'lr':             0.001,       \n",
    "    'weight_decay':   0.001,      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config['csv_path'])\n",
    "\n",
    "df[config['target_col']] = (\n",
    "    df[config['target_col']]\n",
    "      .replace(r'[\\$,]', '', regex=True)\n",
    "      .astype(float)\n",
    ")\n",
    "df['milage'] = (\n",
    "    df['milage']\n",
    "      .replace(r'\\s?mi\\.?', '', regex=True)\n",
    "      .replace(',', '', regex=True)\n",
    "      .astype(float)\n",
    ")\n",
    "\n",
    "df.drop(columns=config['drop_cols'], inplace=True)\n",
    "\n",
    "X = df.drop(columns=[config['target_col']])\n",
    "y = np.log1p(df[config['target_col']].to_numpy(dtype=np.float32))\n",
    "\n",
    "train_frac = config['train_size']\n",
    "temp_frac  = config['val_size'] + config['test_size']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    train_size = train_frac,\n",
    "    random_state= config['random_state']\n",
    ")\n",
    "\n",
    "val_frac = config['val_size'] / temp_frac\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    train_size  = val_frac,\n",
    "    random_state= config['random_state']\n",
    ")\n",
    "\n",
    "num_cols   = config['numeric_cols']\n",
    "num_pipe   = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale',  StandardScaler()),\n",
    "])\n",
    "Xn_train = num_pipe.fit_transform( X_train[num_cols] )\n",
    "Xn_val   = num_pipe.transform(    X_val[  num_cols] )\n",
    "Xn_test  = num_pipe.transform(    X_test[ num_cols] )\n",
    "\n",
    "cat_cols        = config['categorical_cols']\n",
    "encoders        = {}\n",
    "field_dims      = []    \n",
    "Xc_train_cols   = []\n",
    "Xc_val_cols     = []\n",
    "Xc_test_cols    = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    cats = sorted(X_train[col].dropna().unique().tolist())\n",
    "    mapping = {v:i for i,v in enumerate(cats)}\n",
    "    unk_idx = len(cats)           \n",
    "    encoders[col] = mapping\n",
    "    field_dims.append(unk_idx+1)  \n",
    "\n",
    "    def encode_series(s):\n",
    "        return s.map(lambda v: mapping.get(v, unk_idx)).to_numpy()\n",
    "\n",
    "    Xc_train_cols.append( encode_series(X_train[col].fillna('')) )\n",
    "    Xc_val_cols.append(   encode_series(X_val[  col].fillna('')) )\n",
    "    Xc_test_cols.append(  encode_series(X_test[ col].fillna('')) )\n",
    "\n",
    "Xc_train = np.stack(Xc_train_cols, axis=1)\n",
    "Xc_val   = np.stack(Xc_val_cols,   axis=1)\n",
    "Xc_test  = np.stack(Xc_test_cols,  axis=1)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  Xn_train\", Xn_train.shape, \" Xc_train\", Xc_train.shape)\n",
    "print(\"  Xn_val  \",   Xn_val.shape,   \" Xc_val  \",   Xc_val.shape)\n",
    "print(\"  Xn_test \",  Xn_test.shape,  \" Xc_test \",  Xc_test.shape)\n",
    "print(\"  field_dims\", field_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c900a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFM(nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim, mlp_dims, dropout, num_numeric):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.ModuleList([\n",
    "            nn.Embedding(card, embed_dim) for card in field_dims\n",
    "        ])\n",
    "        self.bn = nn.BatchNorm1d(embed_dim)\n",
    "        \n",
    "        input_dim = embed_dim + num_numeric\n",
    "        layers = []\n",
    "        for h in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            input_dim = h\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        embs = torch.stack(\n",
    "            [emb(x_cat[:, i]) for i, emb in enumerate(self.embedding)],\n",
    "            dim=1\n",
    "        )\n",
    "        sum_emb = embs.sum(1)\n",
    "        bi_pool = 0.5 * (sum_emb.pow(2) - embs.pow(2).sum(1))\n",
    "        bi_pool = self.bn(bi_pool)\n",
    "        \n",
    "        x = torch.cat([bi_pool, x_num], dim=1)\n",
    "        return self.mlp(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsedCarDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_num, y):\n",
    "        self.x_cat = torch.tensor(x_cat, dtype=torch.long)\n",
    "        self.x_num = torch.tensor(x_num, dtype=torch.float32)\n",
    "        self.y     = torch.tensor(y,     dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_cat[idx], self.x_num[idx], self.y[idx]\n",
    "    \n",
    "train_ds = UsedCarDataset(Xc_train, Xn_train, y_train)\n",
    "val_ds   = UsedCarDataset(Xc_val,   Xn_val,   y_val)\n",
    "test_ds    = UsedCarDataset(Xc_test, Xn_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=config['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcdf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NFM(\n",
    "    field_dims,\n",
    "    config['embed_dim'],\n",
    "    config['mlp_dims'],\n",
    "    config['dropout'],\n",
    "    len(config['numeric_cols'])\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=200\n",
    ")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "criterion    = F.mse_loss\n",
    "num_epochs   = config['num_epochs']\n",
    "patience     = 150\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_mae_list, val_mae_list = [], []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for xc, xn, y in train_loader:\n",
    "        xc, xn, y = xc.to(device), xn.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(xc, xn)\n",
    "        loss   = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item() * y.size(0)\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xc, xn, y in val_loader:\n",
    "            xc, xn, y = xc.to(device), xn.to(device), y.to(device)\n",
    "            y_pred = model(xc, xn)\n",
    "            running_val_loss += criterion(y_pred, y).item() * y.size(0)\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "    sum_abs_train, cnt_train = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xc, xn, y in train_loader:\n",
    "            xc, xn, y = xc.to(device), xn.to(device), y.to(device)\n",
    "            pr = model(xc, xn)\n",
    "            pred   = torch.expm1(pr)\n",
    "            actual = torch.expm1(y)\n",
    "            sum_abs_train += (pred - actual).abs().sum().item()\n",
    "            cnt_train     += y.size(0)\n",
    "    train_mae = sum_abs_train / cnt_train\n",
    "    train_mae_list.append(train_mae)\n",
    "\n",
    "    sum_abs_val, cnt_val = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xc, xn, y in val_loader:\n",
    "            xc, xn, y = xc.to(device), xn.to(device), y.to(device)\n",
    "            pr = model(xc, xn)\n",
    "            pred   = torch.expm1(pr)\n",
    "            actual = torch.expm1(y)\n",
    "            sum_abs_val += (pred - actual).abs().sum().item()\n",
    "            cnt_val     += y.size(0)\n",
    "    val_mae = sum_abs_val / cnt_val\n",
    "    val_mae_list.append(val_mae)\n",
    "\n",
    "\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"No improvement in {patience} epochs â€” stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    if epoch == 1 or epoch % 50 == 0 or epoch == num_epochs:\n",
    "        print(f\"Epoch {epoch}/{num_epochs}  \"\n",
    "              f\"Train MSE: {epoch_train_loss:.4f}  Val MSE: {epoch_val_loss:.4f}  \"\n",
    "              f\"Train MAE: ${train_mae:,.2f}  Val MAE: ${val_mae:,.2f}\")\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"Train  MSE: {train_losses[-1]:.4f},  MAE: ${train_mae_list[-1]:,.2f}\")\n",
    "print(f\"Val    MSE: {val_losses[-1]:.4f},  MAE: ${val_mae_list[-1]:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "running_test_mse = 0.0\n",
    "sum_abs_test     = 0.0\n",
    "cnt_test         = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xc, xn, y in test_loader:\n",
    "        xc, xn, y = xc.to(device), xn.to(device), y.to(device)\n",
    "        pr = model(xc, xn)\n",
    "        running_test_mse += criterion(pr, y).item() * y.size(0)\n",
    "        pred   = torch.expm1(pr)\n",
    "        actual = torch.expm1(y)\n",
    "        sum_abs_test += (pred - actual).abs().sum().item()\n",
    "        cnt_test     += y.size(0)\n",
    "\n",
    "test_loss = running_test_mse / len(test_loader.dataset)\n",
    "test_mae = sum_abs_test     / cnt_test\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"Train MSE: {train_losses[-1]:.4f},  MAE: ${train_mae_list[-1]:,.2f}\")\n",
    "print(f\"  Val MSE: {val_losses[-1]:.4f},  MAE: ${val_mae_list[-1]:,.2f}\")\n",
    "print(f\" Test MSE: {test_loss:.4f},  MAE: ${test_mae:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a61c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train MSE')\n",
    "plt.plot(val_losses,   label='Val   MSE')\n",
    "plt.yscale('log')\n",
    "plt.title(\"MSE over Epochs (log scale)\", fontsize=14)\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"MSE Loss (log scale)\", fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_mae_list, label='Train MAE')\n",
    "plt.plot(val_mae_list,   label='Val   MAE')\n",
    "plt.title(\"MAE over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Absolute Error ($)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xc, xn, y in test_loader:\n",
    "        xc, xn, y = xc.to(device), xn.to(device), y.to(device)\n",
    "        pr   = model(xc, xn)\n",
    "        pred = torch.expm1(pr)    \n",
    "        real = torch.expm1(y)\n",
    "        y_pred.extend(pred.cpu().numpy().ravel())\n",
    "        y_true.extend(real.cpu().numpy().ravel())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "test_mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Test MAE: ${test_mae:,.2f}\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.3)\n",
    "minv, maxv = y_true.min(), y_true.max()\n",
    "plt.plot([minv, maxv], [minv, maxv], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Price ($)\")\n",
    "plt.ylabel(\"Predicted Price ($)\")\n",
    "plt.ticklabel_format(style='plain', axis='both')\n",
    "plt.title(f\"Actual vs. Predicted on Test Set  (MAE: ${test_mae:,.2f})\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
